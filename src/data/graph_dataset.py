"""PyTorch Dataset for HMS preprocessed graph data."""

from __future__ import annotations

from pathlib import Path
from typing import Dict, List, Tuple, Optional, Callable, Any
import pandas as pd
import torch
from torch.utils.data import Dataset
from torch_geometric.data import Batch


class HMSDataset(Dataset):
    """Dataset for loading preprocessed HMS brain activity graphs.
    
    Loads patient files from data/processed/ where each file contains:
    - patient_id → label_id → {eeg_graphs: List[9], spec_graphs: List[119], target: int}
    
    This dataset works with a metadata DataFrame (from train_unique.csv) to:
    - Filter samples based on fold assignments
    - Access sample metadata (patient_id, label_id, votes, etc.)
    
    Parameters
    ----------
    data_dir : str or Path
        Directory containing preprocessed patient files (patient_*.pt)
    metadata_df : pd.DataFrame
        DataFrame with columns: patient_id, label_id, expert_consensus, *_vote, etc.
        Must have 'fold' column if using for train/val split
    is_train : bool
        Whether this is training set (affects which samples to use based on fold)
    transform : callable, optional
        Optional transform to apply to samples
    """
    
    def __init__(
        self,
        data_dir: str | Path,
        metadata_df: pd.DataFrame,
        is_train: bool = True,
        transform: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None,
        patient_cache_size: int = 2,
    ) -> None:
        self.data_dir = Path(data_dir)
        self.metadata_df = metadata_df.reset_index(drop=True)
        self.is_train = is_train
        self.transform = transform
        self.patient_cache_size = max(0, int(patient_cache_size))
        self._patient_cache: Dict[int, Dict[int, Dict[str, Any]]] = {}
        
        # Build index: list of indices into metadata_df
        self.sample_indices: List[int] = list(range(len(self.metadata_df)))
        
        # Map labels to indices
        self.label_map = {
            'Seizure': 0,
            'LPD': 1,
            'GPD': 2,
            'LRDA': 3,
            'GRDA': 4,
            'Other': 5,
        }
        
    def __len__(self) -> int:
        """Return total number of samples."""
        return len(self.sample_indices)
    
    def __getitem__(self, idx: int) -> Dict:
        """Get a single sample.
        
        Parameters
        ----------
        idx : int
            Sample index
            
        Returns
        -------
        dict
            Dictionary with keys:
            - 'eeg_graphs': List of 9 PyG Data objects
            - 'spec_graphs': List of 119 PyG Data objects
            - 'target': int (0-5)
            - 'patient_id': int
            - 'label_id': int
        """
        # Get metadata for this sample
        sample_idx = self.sample_indices[idx]
        row = self.metadata_df.iloc[sample_idx]
        
        patient_id = int(row['patient_id'])
        label_id = int(row['label_id'])
        
        # Load patient file with a small in-memory cache per worker
        if patient_id in self._patient_cache:
            patient_data = self._patient_cache[patient_id]
        else:
            patient_path = self.data_dir / f"patient_{patient_id}.pt"
            patient_data = torch.load(patient_path, weights_only=False)
            if self.patient_cache_size > 0:
                # Maintain a small cache (LRU by insertion order)
                if len(self._patient_cache) >= self.patient_cache_size:
                    # pop first inserted key
                    old_pid = next(iter(self._patient_cache))
                    self._patient_cache.pop(old_pid, None)
                self._patient_cache[patient_id] = patient_data
        
        # Get specific label data
        sample_data = patient_data[label_id]
        
        # Build target probability vector from vote columns in metadata
        vote_cols = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']
        votes = torch.tensor([float(row[c]) for c in vote_cols], dtype=torch.float32)
        total = float(votes.sum().item())
        if total > 0:
            target_probs = votes / total
        else:
            # Fallback to one-hot of target if no votes available
            target_idx = int(sample_data['target'])
            target_probs = torch.zeros(6, dtype=torch.float32)
            target_probs[target_idx] = 1.0

        # Construct sample
        sample = {
            'eeg_graphs': sample_data['eeg_graphs'],
            'spec_graphs': sample_data['spec_graphs'],
            'target': sample_data['target'],
            'target_probs': target_probs,
            'patient_id': patient_id,
            'label_id': label_id,
        }
        
        if self.transform:
            sample = self.transform(sample)
        
        return sample
    
    def get_class_distribution(self) -> Dict[int, int]:
        """Get distribution of classes in dataset.
        
        Returns
        -------
        dict
            Dictionary mapping class index to count
        """
        class_counts = {}
        
        for sample_idx in self.sample_indices:
            row = self.metadata_df.iloc[sample_idx]
            label = row['expert_consensus'].strip()
            target = self.label_map.get(label, -1)
            
            if target >= 0:
                class_counts[target] = class_counts.get(target, 0) + 1
        
        return class_counts
    
    def get_class_weights(self) -> torch.Tensor:
        """Compute inverse frequency class weights for loss balancing.
        
        Returns
        -------
        torch.Tensor
            Weights of shape (num_classes,)
        """
        class_counts = self.get_class_distribution()
        num_classes = max(class_counts.keys()) + 1
        
        # Count per class
        counts = torch.zeros(num_classes)
        for cls, count in class_counts.items():
            counts[cls] = count
        
        # Compute inverse frequency weights
        total = counts.sum()
        weights = total / (num_classes * counts)
        
        # Normalize so mean weight is 1.0
        weights = weights / weights.mean()
        
        return weights


def collate_graphs(batch: List[Dict]) -> Dict:
    """Collate function for DataLoader to batch graph sequences.
    
    Parameters
    ----------
    batch : List[Dict]
        List of samples from HMSDataset
        
    Returns
    -------
    dict
        Batched data with keys:
        - 'eeg_graphs': List of 9 batched graphs (each is a PyG Batch)
        - 'spec_graphs': List of 119 batched graphs (each is a PyG Batch)
        - 'targets': LongTensor of shape (batch_size,)
        - 'patient_ids': List of patient IDs
        - 'label_ids': List of label IDs
    """
    batch_size = len(batch)
    
    # Extract components
    eeg_sequences = [sample['eeg_graphs'] for sample in batch]  # List[List[9 graphs]]
    spec_sequences = [sample['spec_graphs'] for sample in batch]  # List[List[119 graphs]]
    targets = torch.tensor([sample['target'] for sample in batch], dtype=torch.long)
    target_probs = torch.stack([sample['target_probs'] for sample in batch], dim=0)  # (B, 6)
    patient_ids = [sample['patient_id'] for sample in batch]
    label_ids = [sample['label_id'] for sample in batch]
    
    # Batch EEG graphs: transpose to get 9 lists, each with batch_size graphs
    num_eeg_timesteps = len(eeg_sequences[0])
    batched_eeg_graphs = []
    for t in range(num_eeg_timesteps):
        # Get all graphs at timestep t across batch
        graphs_at_t = [eeg_sequences[b][t] for b in range(batch_size)]
        # Batch them into single PyG Batch object
        batched_graph = Batch.from_data_list(graphs_at_t)
        batched_eeg_graphs.append(batched_graph)
    
    # Batch Spectrogram graphs: same process
    num_spec_timesteps = len(spec_sequences[0])
    batched_spec_graphs = []
    for t in range(num_spec_timesteps):
        graphs_at_t = [spec_sequences[b][t] for b in range(batch_size)]
        batched_graph = Batch.from_data_list(graphs_at_t)
        batched_spec_graphs.append(batched_graph)
    
    return {
        'eeg_graphs': batched_eeg_graphs,  # List[9] of Batch objects
        'spec_graphs': batched_spec_graphs,  # List[119] of Batch objects
        'targets': targets,  # (batch_size,)
        'target_probs': target_probs,  # (batch_size, 6)
        'patient_ids': patient_ids,
        'label_ids': label_ids,
    }


__all__ = ["HMSDataset", "collate_graphs"]
