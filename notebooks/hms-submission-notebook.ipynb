{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on test split (from processed training data)\n",
    "from src.predict import predict\n",
    "pred_out = 'notebooks/outputs/preds_smoke.csv'\n",
    "Path('notebooks/outputs').mkdir(parents=True, exist_ok=True)\n",
    "predict(\n",
    "    config_path='configs/model.yaml',\n",
    "    checkpoint_path=best_ckpt,\n",
    "    output_csv=pred_out,\n",
    "    batch_size_override=4,\n",
    "    num_workers_override=0,\n",
    " )\n",
    "print('Saved predictions to', pred_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate best checkpoint for inference\n",
    "from pathlib import Path\n",
    "ckpt_dir = Path('checkpoints')\n",
    "best_ckpt = None\n",
    "if ckpt_dir.exists():\n",
    "    # Prefer a 'best' symlink/path if present, otherwise latest by mtime\n",
    "    paths = sorted(ckpt_dir.glob('*.ckpt'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    best_ckpt = str(paths[0]) if paths else None\n",
    "print('Best checkpoint:', best_ckpt)\n",
    "assert best_ckpt is not None, 'No checkpoints found after training.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Smoke training (1 epoch, 2 train batches, 1 val batch)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m      3\u001b[39m trainer, model, datamodule = train(\n\u001b[32m      4\u001b[39m     config_path=\u001b[33m'\u001b[39m\u001b[33mconfigs/model.yaml\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     wandb_project=\u001b[33m'\u001b[39m\u001b[33mhms-graphs\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     batch_size_override=\u001b[32m2\u001b[39m, num_workers_override=\u001b[32m0\u001b[39m,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSmoke training done.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# Smoke training (1 epoch, 2 train batches, 1 val batch)\n",
    "from src.train import train\n",
    "trainer, model, datamodule = train(\n",
    "    config_path='configs/model.yaml',\n",
    "    wandb_project='hms-graphs',\n",
    "    wandb_name='smoke-notebook',\n",
    "    smoke=True, offline=True,\n",
    "    limit_train_batches=2, limit_val_batches=1, max_epochs_override=1,\n",
    "    batch_size_override=2, num_workers_override=0,\n",
    ")\n",
    "print('Smoke training done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & Imports\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "print('Project root:', project_root)\n",
    "\n",
    "# WANDB offline for smoke runs\n",
    "os.environ.setdefault('WANDB_MODE', 'offline')\n",
    "print('WANDB_MODE =', os.environ.get('WANDB_MODE'))\n",
    "\n",
    "# Quick data check\n",
    "from pathlib import Path\n",
    "proc_dir = Path('data/processed')\n",
    "assert proc_dir.exists(), f'Missing processed data at {proc_dir}. Run preprocessing first.'\n",
    "patient_files = list(proc_dir.glob('patient_*.pt'))\n",
    "print('Processed patients:', len(patient_files))\n",
    "assert len(patient_files) > 0, 'No processed patient files found.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMS Graphs: Smoke Train + Inference\n",
    "#\n",
    "# This notebook runs a fast smoke test training and a quick inference pass\n",
    "# using the processed graph data in `data/processed/`.\n",
    "# - Training: 1 epoch, 2 train batches, 1 val batch, WANDB offline\n",
    "# - Inference: runs on the test split from processed training data\n",
    "#\n",
    "# After verifying this works, run full training from terminal (see notes below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-01T16:07:01.141675Z",
     "iopub.status.busy": "2025-11-01T16:07:01.140548Z",
     "iopub.status.idle": "2025-11-01T16:07:01.149276Z",
     "shell.execute_reply": "2025-11-01T16:07:01.147956Z",
     "shell.execute_reply.started": "2025-11-01T16:07:01.141641Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: INFERENCE\n",
      "Model Type: MLP\n",
      "  Config: /kaggle/input/repo-whl-dataset/project/configs/training_mlp.yaml\n",
      "  Checkpoint: /kaggle/input/baseline-model/mlp_baseline_best_fold.ckpt\n",
      "  Write to file: True\n",
      "  Output: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# User Settings: pick mode, model type, and config\n",
    "MODE = \"INFERENCE\"  # \"TRAIN\" or \"INFERENCE\"\n",
    "MODEL_TYPE = \"MLP\"  # \"MLP\" or \"GRAPH\"\n",
    "\n",
    "# Training settings (if MODE=\"TRAIN\")\n",
    "TRAIN_CONFIG = \"/kaggle/input/repo-whl-dataset/project/configs/training_mlp.yaml\"  # MLP config\n",
    "# TRAIN_CONFIG = \"configs/training_rnn.yaml\"  # or Graph config\n",
    "TRAIN_FOLDS = [0, 1, 2, 3, 4]  # which folds to train; set to [0] for quick test\n",
    "TRAIN_N_SPLITS = 5  # number of folds for cross-validation\n",
    "\n",
    "# Inference settings (if MODE=\"INFERENCE\")\n",
    "INFERENCE_CONFIG = \"/kaggle/input/repo-whl-dataset/project/configs/training_mlp.yaml\"  # adjust based on checkpoint\n",
    "# INFERENCE_CONFIG = \"configs/inference_merged_small.yaml\"  # for graph models\n",
    "CHECKPOINT_PATH = \"/kaggle/input/baseline-model/mlp_baseline_best_fold.ckpt\"  # path to .ckpt file\n",
    "BATCH_SIZE = 32\n",
    "OUTPUT_CSV = \"submission.csv\"\n",
    "WRITE_TO_FILE = True  # False = keep DataFrame in notebook only, True = write CSV file\n",
    "\n",
    "print(f\"Mode: {MODE}\")\n",
    "print(f\"Model Type: {MODEL_TYPE}\")\n",
    "if MODE == \"TRAIN\":\n",
    "    print(f\"  Config: {TRAIN_CONFIG}\")\n",
    "    print(f\"  Folds: {TRAIN_FOLDS}\")\n",
    "    print(f\"  N Splits: {TRAIN_N_SPLITS}\")\n",
    "else:\n",
    "    print(f\"  Config: {INFERENCE_CONFIG}\")\n",
    "    print(f\"  Checkpoint: {CHECKPOINT_PATH}\")\n",
    "    print(f\"  Write to file: {WRITE_TO_FILE}\")\n",
    "    if WRITE_TO_FILE:\n",
    "        print(f\"  Output: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T16:07:01.151085Z",
     "iopub.status.busy": "2025-11-01T16:07:01.150805Z",
     "iopub.status.idle": "2025-11-01T16:07:01.189770Z",
     "shell.execute_reply": "2025-11-01T16:07:01.188749Z",
     "shell.execute_reply.started": "2025-11-01T16:07:01.151065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Kaggle\n",
      "Dependencies already installed\n",
      "REPO_ROOT = /kaggle/working/project\n",
      "CWD = /kaggle/working/project\n"
     ]
    }
   ],
   "source": [
    "# Environment setup: local vs Kaggle\n",
    "import os, sys, subprocess, shutil, glob\n",
    "from pathlib import Path\n",
    "\n",
    "IS_KAGGLE = os.path.exists('/kaggle')\n",
    "IS_LOCAL = not IS_KAGGLE\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    print(\"Running on Kaggle\")\n",
    "    # Always work inside /kaggle/working (writable)\n",
    "    REPO_ROOT = Path('/kaggle/input/repo-whl-dataset/project')\n",
    "    WHEELS_DIR = Path('/kaggle/input/complete-deps-dataset/wheels')  # adjust to your wheels dataset\n",
    "    \n",
    "    # Helper: find an attached repo dataset under /kaggle/input when Internet is OFF\n",
    "    def _find_repo_dataset():\n",
    "        base = Path('/kaggle/input')\n",
    "        candidates = []\n",
    "        try:\n",
    "            for p in base.iterdir():\n",
    "                # direct repo layout\n",
    "                if (p / 'setup.py').exists() and (p / 'configs').exists():\n",
    "                    candidates.append(p)\n",
    "                # nested under 'project/'\n",
    "                if (p / 'project' / 'setup.py').exists() and (p / 'project' / 'configs').exists():\n",
    "                    candidates.append(p / 'project')\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Prefer names that look like ours if multiple\n",
    "        pref = [c for c in candidates if any(k in str(c).lower() for k in ['hms-kaggle','hms_kaggle','project'])]\n",
    "        if pref:\n",
    "            return pref[0]\n",
    "        return candidates[0] if candidates else None\n",
    "    \n",
    "    # If repo not cloned yet and Internet is ON, clone it; otherwise copy from an attached dataset\n",
    "    if not REPO_ROOT.exists():\n",
    "        try:\n",
    "            print(\"Cloning repo to /kaggle/working ...\")\n",
    "            subprocess.run(['git','clone','--depth','1','--branch','baselines',\n",
    "                           'https://github.com/denskrlv/HMS-Kaggle.git', str(REPO_ROOT)], check=True)\n",
    "        except Exception:\n",
    "            REPO_DATASET = _find_repo_dataset() or Path('/kaggle/input/hms-kaggle-rnn-klloss')\n",
    "            if REPO_DATASET.exists():\n",
    "                print(f\"Copying repo from attached dataset: {REPO_DATASET} -> {REPO_ROOT}\")\n",
    "                os.makedirs('/kaggle/working', exist_ok=True)\n",
    "                os.chdir('/kaggle/working')\n",
    "                shutil.copytree(REPO_DATASET, REPO_ROOT, dirs_exist_ok=True)\n",
    "            else:\n",
    "                raise FileNotFoundError(\"Repo not available; attach repo dataset or enable Internet.\")\n",
    "    \n",
    "    # Absolute safety guard: never operate with REPO_ROOT inside /kaggle/input (read-only)\n",
    "    if str(REPO_ROOT).startswith('/kaggle/input'):\n",
    "        src = REPO_ROOT\n",
    "        REPO_ROOT = Path('/kaggle/working/project')\n",
    "        if not REPO_ROOT.exists():\n",
    "            print(f\"Copying project out of read-only to working dir: {src} -> {REPO_ROOT}\")\n",
    "            shutil.copytree(src, REPO_ROOT, dirs_exist_ok=True)\n",
    "    \n",
    "    # Install wheels if not already installed\n",
    "    try:\n",
    "        import torch_geometric, torcheeg\n",
    "        print(\"Dependencies already installed\")\n",
    "    except Exception:\n",
    "        def pipi(*args): subprocess.run([sys.executable,'-m','pip',*args], check=True)\n",
    "        # PYG stack\n",
    "        pipi('install','--no-index','--no-deps','--find-links',str(WHEELS_DIR),\n",
    "             'pyg_lib','torch_scatter','torch_sparse','torch_cluster','torch_spline_conv','torch_geometric')\n",
    "        # torcheeg deps + torcheeg\n",
    "        pipi('install','--no-index','--find-links',str(WHEELS_DIR),\n",
    "             'spectrum==0.9.0','lmdb>=1.3.0','pywavelets','einops')\n",
    "        te_whl = sorted(glob.glob(str(WHEELS_DIR / 'torcheeg-1.1.2-*.whl')))\n",
    "        if te_whl:\n",
    "            pipi('install','--no-index','--no-deps', te_whl[0])\n",
    "    \n",
    "    # SciPy >= 2.0 compat\n",
    "    import scipy.signal as spsig\n",
    "    try: _ = spsig.hann\n",
    "    except AttributeError:\n",
    "        from scipy.signal import windows as _win\n",
    "        spsig.hann = _win.hann\n",
    "    \n",
    "    # Link competition data into repo layout (under /kaggle/working only)\n",
    "    K_IN = Path('/kaggle/input/hms-harmful-brain-activity-classification')\n",
    "    DATA_RAW = REPO_ROOT / 'data' / 'raw'\n",
    "    DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "    for src, dst in [\n",
    "        (K_IN/'train.csv', DATA_RAW/'train.csv'),\n",
    "        (K_IN/'test.csv', DATA_RAW/'test.csv'),\n",
    "        (K_IN/'train_eegs', DATA_RAW/'train_eegs'),\n",
    "        (K_IN/'train_spectrograms', DATA_RAW/'train_spectrograms'),\n",
    "        (K_IN/'test_eegs', DATA_RAW/'test_eegs'),\n",
    "        (K_IN/'test_spectrograms', DATA_RAW/'test_spectrograms'),\n",
    "    ]:\n",
    "        if src.exists() and not dst.exists():\n",
    "            try: os.symlink(src, dst)\n",
    "            except Exception: (shutil.copytree if src.is_dir() else shutil.copy2)(src, dst)\n",
    "    \n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "    # Find repo root (go up from notebooks/ to HMS-Kaggle/)\n",
    "    current = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "    if current.name == 'notebooks':\n",
    "        REPO_ROOT = current.parent\n",
    "    else:\n",
    "        REPO_ROOT = current\n",
    "    # Assume local workspace already has dependencies and data\n",
    "\n",
    "# Put repo on sys.path\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "os.chdir(REPO_ROOT)\n",
    "print(f\"REPO_ROOT = {REPO_ROOT}\")\n",
    "print(f\"CWD = {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T16:07:01.191260Z",
     "iopub.status.busy": "2025-11-01T16:07:01.190905Z",
     "iopub.status.idle": "2025-11-01T16:07:01.394077Z",
     "shell.execute_reply": "2025-11-01T16:07:01.392701Z",
     "shell.execute_reply.started": "2025-11-01T16:07:01.191231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference (MLP)...\n",
      "Submission will be written to: /kaggle/working/submission.csv\n",
      "Loading checkpoint from /kaggle/input/baseline-model/mlp_baseline_best_fold.ckpt\n",
      "Using device: cpu\n",
      "Building test inputs from data/raw/test.csv and data/raw/test_eegs ...\n",
      "Loaded 1 / 1 EEG files\n",
      "Generated predictions for 1 available samples; 0 missing\n",
      "\n",
      "Submission preview:\n",
      "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
      "0  3911565283      0.357359  0.153703  0.017598   0.097441   0.055846   \n",
      "\n",
      "   other_vote  \n",
      "0    0.318053  \n",
      "\n",
      "Shape: (1, 7)\n",
      "Columns: ['eeg_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "\n",
      "Saved submission to /kaggle/working/submission.csv\n",
      "Wrote /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Run Training or Inference\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "if MODE == \"TRAIN\":\n",
    "    print(f\"Starting training ({MODEL_TYPE})...\")\n",
    "    \n",
    "    if MODEL_TYPE == \"MLP\":\n",
    "        # Call train_mlp with config and n_splits\n",
    "        import src.train_mlp as tm\n",
    "        importlib.reload(tm)\n",
    "        sys.argv = [\n",
    "            \"train_mlp.py\",\n",
    "            \"--config\", str(TRAIN_CONFIG),\n",
    "            \"--n_splits\", str(TRAIN_N_SPLITS),\n",
    "        ]\n",
    "        # Optional debug flag: set by user before running\n",
    "        if \"--fast_dev_run\" in sys.argv:\n",
    "            sys.argv.append(\"--fast_dev_run\")\n",
    "        tm.main()\n",
    "        \n",
    "    elif MODEL_TYPE == \"GRAPH\":\n",
    "        # Call train_model with config and folds\n",
    "        import src.train_model as tm\n",
    "        importlib.reload(tm)\n",
    "        sys.argv = [\n",
    "            \"train_model.py\",\n",
    "            \"--config\", str(TRAIN_CONFIG),\n",
    "            \"--folds\",\n",
    "            *[str(f) for f in TRAIN_FOLDS],\n",
    "        ]\n",
    "        tm.main()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown MODEL_TYPE: {MODEL_TYPE}\")\n",
    "    \n",
    "elif MODE == \"INFERENCE\":\n",
    "    print(f\"Starting inference ({MODEL_TYPE})...\")\n",
    "    \n",
    "    # Decide a submission path OUTSIDE the project folder\n",
    "    # - On Kaggle: /kaggle/working/<OUTPUT_CSV>\n",
    "    # - Locally: parent of REPO_ROOT, keeping the same filename\n",
    "    base_out_dir = Path('/kaggle/working') if ('IS_KAGGLE' in globals() and IS_KAGGLE) else Path(REPO_ROOT).parent\n",
    "    SUBMISSION_PATH = (base_out_dir / Path(OUTPUT_CSV).name).resolve()\n",
    "    if WRITE_TO_FILE or MODEL_TYPE == \"GRAPH\":\n",
    "        print(f\"Submission will be written to: {SUBMISSION_PATH}\")\n",
    "    \n",
    "    if MODEL_TYPE == \"MLP\":\n",
    "        # Call predict_mlp with config and checkpoint\n",
    "        import src.predict_mlp as pm\n",
    "        importlib.reload(pm)\n",
    "        argv = [\n",
    "            \"predict_mlp.py\",\n",
    "            \"--config\", str(INFERENCE_CONFIG),\n",
    "            \"--checkpoint\", str(CHECKPOINT_PATH),\n",
    "            \"--batch_size\", str(BATCH_SIZE),\n",
    "        ]\n",
    "        if WRITE_TO_FILE:\n",
    "            argv += [\"--output\", str(SUBMISSION_PATH)]\n",
    "        sys.argv = argv\n",
    "        submission_df = pm.main()\n",
    "        \n",
    "    elif MODEL_TYPE == \"GRAPH\":\n",
    "        # Call predict_model with config and checkpoint (this script always writes a CSV)\n",
    "        import src.predict_model as pm\n",
    "        importlib.reload(pm)\n",
    "        sys.argv = [\n",
    "            \"predict_model.py\",\n",
    "            \"--config\", str(INFERENCE_CONFIG),\n",
    "            \"--checkpoint\", str(CHECKPOINT_PATH),\n",
    "            \"--output\", str(SUBMISSION_PATH),\n",
    "            \"--batch_size\", str(BATCH_SIZE),\n",
    "        ]\n",
    "        submission_df = pm.main()\n",
    "        # If the script doesn't return a DataFrame, load the file for notebook use\n",
    "        if not WRITE_TO_FILE:\n",
    "            import pandas as pd\n",
    "            try:\n",
    "                submission_df = pd.read_csv(SUBMISSION_PATH)\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Prediction file '{SUBMISSION_PATH}' was not created: {e}\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown MODEL_TYPE: {MODEL_TYPE}\")\n",
    "    \n",
    "    if WRITE_TO_FILE:\n",
    "        print(f\"Wrote {SUBMISSION_PATH}\")\n",
    "    else:\n",
    "        print(\"Submission DataFrame kept in notebook (variable: submission_df)\")\n",
    "        if submission_df is not None:\n",
    "            print(f\"Shape: {submission_df.shape}\")\n",
    "            print(submission_df.head())\n",
    "        else:\n",
    "            print(\"submission_df is None\")\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"Unknown MODE: {MODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T16:07:01.396065Z",
     "iopub.status.busy": "2025-11-01T16:07:01.395646Z",
     "iopub.status.idle": "2025-11-01T16:07:01.414555Z",
     "shell.execute_reply": "2025-11-01T16:07:01.412814Z",
     "shell.execute_reply.started": "2025-11-01T16:07:01.396034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission rows: 1 | Test rows: 1\n",
      "Columns: ['eeg_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
      "0  3911565283      0.357359  0.153703  0.017598   0.097441   0.055846   \n",
      "\n",
      "   other_vote  \n",
      "0    0.318053  \n",
      "Missing eeg_ids in submission: 0\n",
      "Submission ready for download at: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Validate submission (only runs if MODE=\"INFERENCE\")\n",
    "if MODE == \"INFERENCE\":\n",
    "    import pandas as pd\n",
    "    \n",
    "    VOTE_KEYS = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\n",
    "    \n",
    "    # Load submission from file or use the returned DataFrame\n",
    "    if WRITE_TO_FILE:\n",
    "        sub = pd.read_csv(SUBMISSION_PATH)\n",
    "    else:\n",
    "        sub = submission_df\n",
    "    \n",
    "    test = pd.read_csv(REPO_ROOT / \"data/raw/test.csv\")\n",
    "    \n",
    "    print(\"Submission rows:\", len(sub), \"| Test rows:\", len(test))\n",
    "    print(\"Columns:\", list(sub.columns))\n",
    "    print(sub.head(3))\n",
    "    \n",
    "    # Basic checks\n",
    "    assert \"eeg_id\" in sub.columns, \"eeg_id column missing\"\n",
    "    for k in VOTE_KEYS:\n",
    "        assert k in sub.columns, f\"Missing column: {k}\"\n",
    "    \n",
    "    missing = set(test[\"eeg_id\"]) - set(sub[\"eeg_id\"])\n",
    "    print(\"Missing eeg_ids in submission:\", len(missing))\n",
    "    \n",
    "    if WRITE_TO_FILE:\n",
    "        print(\"Submission ready for download at:\", SUBMISSION_PATH)\n",
    "    else:\n",
    "        print(\"Submission DataFrame available as 'submission_df' in notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "isSourceIdPinned": false,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 8611582,
     "sourceId": 13557778,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8612852,
     "sourceId": 13559487,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8612404,
     "sourceId": 13578948,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8626737,
     "sourceId": 13578958,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "graph-ml-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
